% 
% exemplo genérico de uso da classe iiufrgs.cls
% $Id: iiufrgs.tex,v 1.1.1.1 2005/01/18 23:54:42 avila Exp $
% 
% This is an example file and is hereby explicitly put in the
% public domain.
% 
\documentclass[cic,tc]{iiufrgs}
% Para usar o modelo, deve-se informar o programa e o tipo de documento.
% Programas :
% * cic       -- Graduação em Ciência da Computação
% * ecp       -- Graduação em Ciência da Computação
% * ppgc      -- Programa de Pós Graduação em Computação
% * pgmigro   -- Programa de Pós Graduação em Microeletrônica
% 
% Tipos de Documento:
% * tc                -- Trabalhos de Conclusão (apenas cic e ecp)
% * diss ou mestrado  -- Dissertações de Mestrado (ppgc e pgmicro)
% * tese ou doutorado -- Teses de Doutorado (ppgc e pgmicro)
% * ti                -- Trabalho Individual (ppgc e pgmicro)
% 
% Outras Opções:
% * english    -- para textos em inglês
% * openright  -- Força início de capítulos em páginas ímpares (padrão da
% biblioteca)
% * oneside    -- Desliga frente-e-verso
% * nominatalocal -- Lê os dados da nominata do arquivo nominatalocal.def


% Use unicode
\usepackage[utf8]{inputenc}   % pacote para acentuação

% Necessário para incluir figuras
\usepackage{graphicx}         % pacote para importar figuras

\usepackage{times}            % pacote para usar fonte Adobe Times
% \usepackage{palatino}
% \usepackage{mathptmx}       % p/ usar fonte Adobe Times nas fórmulas

\usepackage[alf,abnt-emphasize=bf]{abntex2cite}	% pacote para usar citações abnt

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tipa}


% 
% Informações gerais
% 
\title{Juntando as peças: Investigando o Impacto de segmentação morfológica no BERT}

\author{Westhelle}{Matheus}

% orientador e co-orientador são opcionais (não diga isso pra eles :))
\advisor[Profa.~Dra.]{Moreira}{Viviane}
\coadvisor[]{Bencke}{Luciana}

% a data deve ser a da defesa; se nao especificada, são gerados
% mes e ano correntes
% \date{maio}{2001}

% o local de realização do trabalho pode ser especificado (ex. para TCs)
% com o comando \location:
% \location{Itaquaquecetuba}{SP}

% itens individuais da nominata podem ser redefinidos com os comandos
% abaixo:
% \renewcommand{\nominataReit}{Prof\textsuperscript{a}.~Wrana Maria Panizzi}
% \renewcommand{\nominataReitname}{Reitora}
% \renewcommand{\nominataPRE}{Prof.~Jos{\'e} Carlos Ferraz Hennemann}
% \renewcommand{\nominataPREname}{Pr{\'o}-Reitor de Ensino}
% \renewcommand{\nominataPRAPG}{Prof\textsuperscript{a}.~Joc{\'e}lia Grazia}
% \renewcommand{\nominataPRAPGname}{Pr{\'o}-Reitora Adjunta de P{\'o}s-Gradua{\c{c}}{\~a}o}
% \renewcommand{\nominataDir}{Prof.~Philippe Olivier Alexandre Navaux}
% \renewcommand{\nominataDirname}{Diretor do Instituto de Inform{\'a}tica}
% \renewcommand{\nominataCoord}{Prof.~Carlos Alberto Heuser}
% \renewcommand{\nominataCoordname}{Coordenador do PPGC}
% \renewcommand{\nominataBibchefe}{Beatriz Regina Bastos Haro}
% \renewcommand{\nominataBibchefename}{Bibliotec{\'a}ria-chefe do Instituto de Inform{\'a}tica}
% \renewcommand{\nominataChefeINA}{Prof.~Jos{\'e} Valdeni de Lima}
% \renewcommand{\nominataChefeINAname}{Chefe do \deptINA}
% \renewcommand{\nominataChefeINT}{Prof.~Leila Ribeiro}
% \renewcommand{\nominataChefeINTname}{Chefe do \deptINT}

% A seguir são apresentados comandos específicos para alguns
% tipos de documentos.

% Relatório de Pesquisa [rp]:
% \rp{123}             % numero do rp
% \financ{CNPq, CAPES} % orgaos financiadores

% Trabalho Individual [ti]:
% \ti{123}     % numero do TI
% \ti[II]{456} % no caso de ser o segundo TI

% Monografias de Especialização [espec]:
% \espec{Redes e Sistemas Distribuídos}      % nome do curso
% \coord[Profa.~Dra.]{Weber}{Taisy da Silva} % coordenador do curso
% \dept{INA}                                 % departamento relacionado

% 
% palavras-chave
% iniciar todas com letras minúsculas, exceto no caso de abreviaturas
% 
\keyword{Processamento de Linguagem Natural}
\keyword{Linguística Computacional}
\keyword{Representações de palavras}
\keyword{Aprendizado de máquina}

%\settowidth{\seclen}{1.10~}

% 
% inicio do documento
% 
\begin{document}

% folha de rosto
% às vezes é necessário redefinir algum comando logo antes de produzir
% a folha de rosto:
% \renewcommand{\coordname}{Coordenadora do Curso}
\maketitle

% dedicatoria
% \clearpage
% \begin{flushright}
%     \mbox{}\vfill
%     {\sffamily\itshape
%       ``If I have seen farther than others,\\
%       it is because I stood on the shoulders of giants.''\\}
%     --- \textsc{Sir~Isaac Newton}
% \end{flushright}

% agradecimentos
%\chapter*{Agradecimentos}
%Agradeço ao \LaTeX\ por não ter vírus de macro\ldots



% resumo na língua do documento
\begin{abstract}
    Lorem ipsum
\end{abstract}

% resumo na outra língua
% como parametros devem ser passados o titulo e as palavras-chave
% na outra língua, separadas por vírgulas
\begin{englishabstract}{Putting the Pieces Together - investigating the impact of morphological segmentation in BERT}{Natural Language Processing. Computational Linguistics. Word representations. Machine Learning}
    Lorem ipsum
\end{englishabstract}

% lista de figuras
\listoffigures

% lista de tabelas
\listoftables

% lista de abreviaturas e siglas
% o parametro deve ser a abreviatura mais longa
\begin{listofabbrv}{SPMD}
    \item[BERT] Bidirectional Encoder Representations from Transformers
    \item[BPE] Byte Pair Encoding
\end{listofabbrv}

% idem para a lista de símbolos
% \begin{listofsymbols}{$\alpha\beta\pi\omega$}
%     \item[$\sum{\frac{a}{b}}$] Somatório do produtório
%     \item[$\alpha\beta\pi\omega$] Fator de inconstância do resultado
% \end{listofsymbols}

% sumario
\tableofcontents

% aqui comeca o texto propriamente dito

% introducao
\chapter{Introdução}
Modelos de \emph{embeddings} de palavras contextualizados \cite{peters-etal-2018-deep} representam o estado da arte em processamento de linguagem natural, apresentando excelente desempenho em muitas tarefas. Uma das razões do sucesso desses modelos é a segmentação de \emph{tokens} em sub-palavras, que permite a esses modelos lidar com palavras fora de vocabulário, além de aprender a generalizar sequências de caracteres frequentes. Dentre as técnicas de segmentação utilizadas, destacam-se \emph{byte pair encoding} \cite{sennrich-etal-2016-neural} e \emph{WordPiece} \cite{Wu2016GooglesNM}. Essas técnicas funcionam muito bem empiricamente, entretanto elas são pouco capazes de codificar morfologia \cite{klein-tsarfaty-2020-getting}.

Inicialmente motivados pelo DelBERT \cite{Hofmann2021SuperbizarreIN}, nós propomos a criação de um modelo que utilize uma técnica alternativa de segmentação que carregue informação morfológica. Para tanto, utilizamos um modelo não supervisionado de descoberta de morfemas \cite{creutz-lagus-2002-unsupervised}, de forma a inserir tal informação em um modelo de \emph{embeddings} contextualizados. Nossa hipótese é de que o modelo seja capaz de computar o significado de palavras fora de seu vocabulário a partir da composição de seus morfemas, da mesma forma que seres humanos o fazem. Nós então propomos avaliar o desempenho deste modelo em uma série de tarefas, como classificação de texto, \emph{textual entailment}, e \emph{question answering}. Por outro lado, também há evidências de que alta complexidade morfológica aumenta a dificuldade na criação de modelos de linguagem, e de que métodos de segmentação linguisticamente motivados reduzem o impacto dessa complexidade \cite{morphology-matters-tacl-2021}.

\chapter{Fundamentação Teórica}
\section{Morfologia}
\subsection{Morfemas e morfes}
Morfemas são comumente definidos como a menor unidade que constitui uma palavra, um átomo de significado. O morfema é ainda uma abstração em relação a morfes, as realizações de um morfema. Um exemplo elucidativo é o morfema \emph{-s}, marcador de plural em português. Ao construirmos o plural de \emph{casa}, simplesmente sufixamos a palavra com \emph{s}: \emph{casa + s $\rightarrow$ casas}. Entretanto, ao considerarmos o plural de \emph{mês} ou \emph{lápis}, observamos diferentes morfes de \emph{-s}: \emph{-es}, em \emph{meses}, e $\varnothing$, em \emph{lápis} \footnote{O caso em que o morfe não é aparente é conhecido como \emph{morfe zero}.}, respectivamente.

\subsection{Segmentação morfológica}
A tarefa de segmentação morfológica consiste em dividir uma \emph{forma de superfície} em todos os morfes que a compõem. Tomemos um exemplo:

\begin{center}
    superbizarro $\rightarrow$ super + bizarr + a
\end{center}

A palavra \emph{superbizarra} pode ser quebrada em três morfes: \emph{super-}, um prefixo; \emph{bizarr}, a raiz da palavra; e \emph{-a}, desinência de gênero.

Identificar os limites de cada morfe de uma palavra é uma tarefa que exige conhecimento linguístico e apresenta alta variabilidade de dificuldade entre línguas. Para línguas isolantes, como o mandarim, a tarefa é trivial, pois predominam morfemas livres, que formam palavras inteiras por si.

Para línguas polissínteticas, como o idioma esquimó Kalaallisut, a tarefa se torna extremamente difícil, pois uma palavra pode conter múltiplas raizes \cite{morph-typology}.


\section{Morfessor}
O Morfessor \cite{creutz-lagus-2002-unsupervised,Creutz04inductionof,Creutz05inducingthe,Creutz05unsupervisedmorpheme,creutz-lagus-2007-unsupervised} é uma família de algoritmos não supervisionados que atacam o problema da segmentação morfológica, ou seja, a quebra de palavras em seus morfemas. Morfessor também é o nome pelo qual sua implementação em software é conhecida, cuja última versão é a 2.0 \cite{Virpioja2013Morfessor2P} e estende o algoritmo conhecido como Morfessor Baseline \cite{creutz-lagus-2002-unsupervised, Creutz05unsupervisedmorpheme}.

Estes algoritmos são modelos probabilísticos que induzem a criação de um modelo de linguagem de forma não supervisionada e executam um algoritmo de busca gulosa para encontrar o léxico (conjunto de morfes) e segmentações ótimos \cite{Creutz05unsupervisedmorpheme}. É importante desambiguar o termo \emph{modelo de linguagem}; neste contexto, diferentemente de \cite{a-neural-probabilistic-lm}, o modelo de linguagem referido é um vocabulário (ou \emph{léxico}) de morfes e uma gramática, induzidos por aprendizado não-supervisionado.

Lembramos que a tarefa de segmentação morfológica é muito difícil, mesmo para anotadores humanos, e que o Morfessor é meramente uma ferramenta automática, longe da qualidade de um analisador morfológico feito à mão.


\section{Algoritmos de segmentação em sub-palavras}
\subsection{Byte Pair Encoding}

\subsection{WordPiece}

\section{BERT}


\chapter{Materiais e Métodos}
\section{Segmentação baseada em morfemas}
\section{Modelo de Linguagem com Mascaramento}
\subsection{Corpus de treino}
O corpus utilizado para o treinamento dos modelos foi um \emph{dump} da Wikipedia \footnote{https://dumps.wikimedia.org/}. O texto foi extraído e limpo utilizando a ferramenta \emph{WikiExtractor} \footnote{https://github.com/attardi/wikiextractor/}. A seguir, utilizamos \emph{BlingFire} \footnote{https://github.com/microsoft/BlingFire} para criar um dataset de uma frase por linha. Para o pré-treino dos modelos, utilizamos apenas 15\% deste dataset.

\section{Tarefas de avaliação}
\subsection{Classificação de Texto}
\subsubsection{Tarefa}
\subsubsection{Datasets}
\subsection{Recognizing Textual Entailment}
\subsubsection{Tarefa}
\subsubsection{Dataset}
\subsection{Question Answering}
\subsubsection{Tarefa}
\subsubsection{Dataset}

\chapter{Resultados}

\bibliographystyle{abntex2-alf}
\bibliography{biblio}

\end{document}
